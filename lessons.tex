
\section{Reflections on my research experience}
Before we conclude, this section will reflect on the undergraduate research
journey as experienced by the author, Chris Cotter. I initially read
Aviram et al.'s ``Efficient System-Enforced Deterministic Parallelism'' paper
in July of 2011 and wrote my first line of code in the Linux kernel that August.
After many implementation iterations, my final implementation of deterministic
Linux took up the month of September 2012, and I wrote this thesis soon after.

\paragraph{Learning the Kernel}
There is no ``Linux Kernel 101'' course at the University, and most existing
documentation and comments in kernel code are written for seasoned kernel
programmers. Thus, I very often found myself lost and frustrated. It wasn't
until I spent a year (August 2011 - 2012) of kernel hacking until I finally
felt comfortable implementing my third and final iteration of deterministic
Linux.

\subsection{First Iteration}
In August 2011, I began by downloading Linux 2.6.32 source and learned to
compile and run the kernel with {\tt QEMU}~\cite{qemu}. I ran
{\tt QEMU} with a ramdisk containing a single program to run as \emph{init}.
My advisor Mike Walfish gave me my first goal: to implement a new syscall
in Linux. After scouring the Internet, I learned how to do this, and I wrote
skeleton code for my three syscalls: {\tt dput()}, {\tt dget()}, and
{\tt dret()}.

I iteratively implemented Determinator's functionality in these syscalls,
starting with process organization and moving to memory operations. I had a
particularly difficult time with memory operations. Even though I was a wizard
with my operating system's instructional {\tt JOS} OS and page table management,
I had no idea how to maneuver in Linux's memory subsystem.

After fumbling around with countless kernel panics, I set out with a simple
goal: to change a single page table entry. After accomplishing this goal,
I was ready to implement Determinator's Zero and Copy operations. In fact, I
eventually found I could reuse and adapt a lot of existing code for these
operations. Implementing Merge took considerably more effort, since Merge in
Linux is an entirely novel operation.

Unfortunately, this version of my implementation was buggy, primarily due to
misuse of internal kernel API and race conditions in my kernel code.

\subsection{Second Iteration}
In November 2011, I downloaded Linux 2.6.38 source and began rewriting my code,
copying and pasting most of my first iteration code. I also started running
an Arch Linux distribution on QEMU, since I was able to run more sophisticated
tests with an actual Linux distribution running my kernel. With a few months of
kernel hacking knowledge under my belt, I identified many logic bugs and had a
better understanding of how things worked ``under the hood''. Unfortunately, I
encountered many setbacks.

\paragraph{New Memory Features}
Moving from Linux 2.6.32 to 2.6.38 introduced new memory subsystem features.
Notable among these was transparent huge pages (THP). When processes map a large
enough region of virtual memory (e.g., at least 4MB), the kernel will sometimes
fulfill demand paging requests with huge pages without the user knowing.

Since my original code did not account for THP, a lot of my existing kernel code
broke, and I spent days trying to understand what went wrong and perhaps a week
devising a solution. In the end, I came to realize I still lacked a great deal
of knowledge about Linux's memory subsystem, and this lack of knowledge would
continue to plague my second iteration's quality.

\paragraph{Condition Variable Usage Violation}
My operating systems professor Mike Walfish taught us to always surround
the testing of condition variables with a while-loop and not an if-statement.
Unfortunately, I completely disregarded this lesson at some point in my
implementation of {\tt dput()} synchronization, and I found threads being
woken up prematurely.

\paragraph{Snapshot/Merge Bug}
When I ran a stress test to fork hundreds of processes then did a simple
Snapshot and Merge, I encountered a kernel panic that caused unrelated processes
to crash (e.g., {\tt bash}). Through the course of a month, I never identified
the issue except to say that my lack of a thorough understanding of the memory
subsystem was at fault. This, and a general lack of organization in my code lead
me to write a third iteration.

\subsection{Final Iteration}
In September 2012, I forked a copy of the Linux {\tt git} repository and
started with Linux 3.0. I started running my code on an 8-core machine with
8GB of RAM; the 8 cores maximized parallelism to help expose concurrency
bugs in my kernel code. I also decided to do a complete rewrite --- no old code
from previous iterations would be copied and pasted.

After a year of kernel hacking, I had never felt more confident in the code I
wrote; whereas in my second iteration I was not confident in my code's
correctness, in my third iteration I could explain nearly every part of the
kernel that my code interacted with.

\paragraph{General Success}
As I wrote and tested code, I often found that my code worked on the first or
second try. This was primarily due to careful and thoughtful reasoning about
anything I wrote. In previous iterations, I often wrote code and ran it without
fully knowing what to expect.

\paragraph{Squashing the Snapshot Bug}
Through the process of rewriting, I identified the Snapshot/Merge bug described
above: I did not acquire a spinlock when operating on sensitive kernel data
structures in my Snapshot code path. Unfortunately, this spinlock had very
little accompanying documentation, and it was only through many months of
kernel hacking that I even knew to use the spinlock.

\endinput

